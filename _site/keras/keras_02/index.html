<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[keras 뿌시기] 자연어처리를 이용한 이진분류 - Just Do it</title>
<meta name="description" content="IMDB 데이터셋을 활용한 이진분류">


  <meta name="author" content="Tae Hyeon Kim">
  
  <meta property="article:author" content="Tae Hyeon Kim">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="Just Do it">
<meta property="og:title" content="[keras 뿌시기] 자연어처리를 이용한 이진분류">
<meta property="og:url" content="http://localhost:4000/keras/keras_02/">


  <meta property="og:description" content="IMDB 데이터셋을 활용한 이진분류">







  <meta property="article:published_time" content="2023-06-06T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/keras/keras_02/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Tae Hyeon Kim",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Just Do it Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png">
<link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Just Do it
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">Introduce</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Tae Hyeon Kim</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>I am an <strong>amazing</strong> person.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Somewhere</span>
        </li>
      

      
        
          
            <li><a href="mailto:ttth000221@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/Tae-Hyeon-Kim" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[keras 뿌시기] 자연어처리를 이용한 이진분류">
    <meta itemprop="description" content="IMDB 데이터셋을 활용한 이진분류">
    <meta itemprop="datePublished" content="2023-06-06T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/keras/keras_02/" class="u-url" itemprop="url">[keras 뿌시기] 자연어처리를 이용한 이진분류
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-06-06T00:00:00+09:00">June 6, 2023</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 분 소요
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On This Page</h4></header>
              <ul class="toc__menu"><li><a href="#imdb-데이터셋">IMDB 데이터셋</a></li><li><a href="#멀티-핫-인코딩">멀티 핫 인코딩</a></li><li><a href="#이진분류">이진분류</a></li></ul>

            </nav>
          </aside>
        
        <p>IMDB 데이터셋을 활용한 이진분류</p>

<blockquote>
  <p>이미지 자료나 코드 모두 한경훈 교수님의 자료에서 참조하였으며, 한경훈 교수님의 블로그 링크를 첨부합니다. <br />
블로그 링크 : <a href="https://sites.google.com/site/kyunghoonhan/keras?authuser=0">https://sites.google.com/site/kyunghoonhan/keras?authuser=0</a>
—</p>
</blockquote>

<h1 id="imdb-데이터셋">IMDB 데이터셋</h1>
<p>IMDB 데이터셋은 영화 리뷰에 대한 데이터로 리뷰가 긍정적인지 부정적인지에 대한 예측을 할 수 있습니다.</p>

<p>케라스의 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb"><strong>tf.keras.datasets.imdb</strong></a>로부터 IMDB 데이터셋을 불러올 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras.datasets</span> <span class="kn">import</span> <span class="n">imdb</span>
<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="p">.</span><span class="nf">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"훈련용 : </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"테스트용 : </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>훈련용 : 25000
테스트용 : 25000
</pre></td></tr></tbody></table></code></pre></div></div>

<p>리뷰에 등장한 모든 단어를 처리할 수 없기때문에 (정보대비 계산비용이 큼)<br />
등장빈도가 낮다면 <code class="language-plaintext highlighter-rouge">unknown</code>으로 전처리될 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">num_words = 10000</code>이라면 등장빈도가 10,000등 안에 들지 않는 단어들은 <code class="language-plaintext highlighter-rouge">unknown</code>으로 전처리됩니다.</p>

<p>첫번째 훈련 데이터를 출력해보겠습니다.<br />
정수열이 출력됩니다.<br />
라벨을 출력해보니 긍정리뷰라는 것을 알 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">10</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">train_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>1
</pre></td></tr></tbody></table></code></pre></div></div>

<p>각 정수는 등장빈도 순위를 나타내며 <br />
<code class="language-plaintext highlighter-rouge">[가장 많이 등장한 단어, 14번 째로 많이 등장한 단어, ..]</code>로 구성되어 있는 리뷰입니다.<br />
그 단어가 뭔지 알기 위해선 사전이 필요합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">word_index</span> <span class="o">=</span> <span class="n">imdb</span><span class="p">.</span><span class="nf">get_word_index</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">word_index</span><span class="p">[</span><span class="s">'the'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">word_index</span><span class="p">[</span><span class="s">'and'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">word_index</span><span class="p">[</span><span class="s">'a'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>1
2
3
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">word_index</code>는 영어 단어를 정수로 바꾸어주는 사전입니다.<br />
첫 번째 데이터를 확인하기 위해서는 정수를 영어단어로 바꾸어주는 사전이 필요합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">reverse_word_index</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">([(</span><span class="n">value</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="nf">for </span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">word_index</span><span class="p">.</span><span class="nf">items</span><span class="p">()])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">reverse_word_index</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">reverse_word_index</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">reverse_word_index</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>the
and
a
</pre></td></tr></tbody></table></code></pre></div></div>

<p>이제 <code class="language-plaintext highlighter-rouge">reverse_word_index</code>를 활용하여 첫 번째 데이터를 디코딩 할 수 있지만 여기서 주의할 점이 있습니다.<br />
정수로 이루어진 데이터에서 (훈련데이터와 테스트 데이터 모두) 0,1,2,3은 특별 토큰을 나타냅니다.</p>
<ul>
  <li>0 : <code class="language-plaintext highlighter-rouge">&lt;PAD&gt;</code> (문장의 길이가 같아지도록 끼워넣는 더미, 여기서는 사용안함)</li>
  <li>1 : <code class="language-plaintext highlighter-rouge">&lt;START&gt;</code> (문장의 시작을 알림)</li>
  <li>2 : <code class="language-plaintext highlighter-rouge">&lt;UNK&gt;</code> (등장빈도가 낮은 어휘)</li>
  <li>3 : <code class="language-plaintext highlighter-rouge">&lt;UNUSED&gt;</code></li>
</ul>

<p>따라서 제가 첫번째 훈련데이터에 대하여 <br />
<code class="language-plaintext highlighter-rouge">[가장 많이 등장한 단어, 14번 째로 많이 등장한 단어, ..]</code>로 구성되어 있다고 한 설명은 사실 틀렸습니다.<br />
<code class="language-plaintext highlighter-rouge">1</code>은 문장의 시작을 알리는 토큰이며 <code class="language-plaintext highlighter-rouge">14</code>는 11번 째로 많이 등장한 단어입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">decoded_review</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">reverse_word_index</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="s">"?"</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">decoded_review</span><span class="p">[:</span><span class="mi">39</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>'? this film was just brilliant casting '
</pre></td></tr></tbody></table></code></pre></div></div>

<p>첫 번째 훈련데이터는 캐스팅에 대해 긍정적인 리뷰였네요.</p>

<hr />

<h1 id="멀티-핫-인코딩">멀티 핫 인코딩</h1>

<p>리뷰 데이터를 신경망으로 학습시키기 위해서는 입력 크기가 같아야합니다.<br />
하지만 리뷰들은 각각 다른 길이의 정수열로 인코딩되어 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>218
189
141
</pre></td></tr></tbody></table></code></pre></div></div>

<p>모두 10,000의 길이를 가지는 멀티 핫 벡터로 다시 인코딩하겠습니다.
그러면 신경망의 입력 뉴런수가 10,000으로 결정될 수 있습니다.
규칙은 다음과 같습니다.</p>

<ul>
  <li>벡터의 길이는 어휘의 개수</li>
  <li>한번이라도 등장하는 인덱스의 자리에는 1 (여러번 중복되도 여전히 1)</li>
  <li>등장하지 않는 인덱스의 자리에는 0</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">vectorize_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span> <span class="c1"># sequences : 리뷰 데이터
</span>    <span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">),</span> <span class="n">dimension</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">:</span>
            <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
    <span class="k">return</span> <span class="n">results</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="nf">vectorize_sequences</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="nf">vectorize_sequences</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_labels</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_labels</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>array([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">vectorize_sequences</code> 함수의 <code class="language-plaintext highlighter-rouge">dimension</code>는 벡터의 차원을 결정합니다.<br />
저희는 처음 데이터를 불러올 때 등장빈도가 10,000등 안에 드는 단어들만을 불러왔습니다. 따라서 등장빈도를 다르게 불러온다면 <code class="language-plaintext highlighter-rouge">dimension</code>의 값을 다르게 줄 수 있습니다.</p>

<hr />

<h1 id="이진분류">이진분류</h1>

<p>입력 뉴런 수를 통일하였으니 이제 신경망을 구성할 수 있습니다.<br />
이진 분류는 마지막 뉴런 수를 2로 잡고 소프트맥스를 사용하기보다는 마지막 뉴런 수를 1로 잡고 시그모이드 함수를 사용합니다.<br />
시그모이드 함수의 출력값은 0~1 사이 값이기 때문에 출력값으로 0.6이 나왔다면, 긍정 확률이 0.6 부정확률이 0.4라고 할 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">keras</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10000</span><span class="p">,),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="nf">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">show_layer_activations</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/122070432/244593942-f5ce4542-9003-4529-961c-422af1f93cc2.png" alt="png" /></p>

<p>학습설정을 합니다.<br />
이전에 손실함수를 설정할 때에는 정수 라벨이라면 <code class="language-plaintext highlighter-rouge">sparse_categorical_crossentropy</code>를, 원핫인코딩이 되어있다면 <code class="language-plaintext highlighter-rouge">categorial_crossentropy</code>를 사용한다고 했습니다.<br />
이진분류를 할때는 손실함수를 <code class="language-plaintext highlighter-rouge">binary_crossentropy</code>로 설정합니다.</p>

<hr />

<ul>
  <li>다중분류, 정수라벨 : <code class="language-plaintext highlighter-rouge">sparse_categorical_crossentropy</code></li>
  <li>다중분류, 원핫인코딩 : <code class="language-plaintext highlighter-rouge">categorial_crossentropy</code></li>
  <li>이진분류 : <code class="language-plaintext highlighter-rouge">binary_crossentropy</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"rmsprop"</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">"binary_crossentropy"</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="s">"accuracy"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>데이터는 통상적으로 훈련 데이터 (train data), 검증 데이터(validation data), 테스트 데이터(test data) 셋으로 나눕니다.<br />
검증 데이터는 최적의 하이퍼 파라미터 값을 찾기 위해 사용됩니다.<br />
하이퍼 파라미터란 학습률, 학습회수, 파라미터 수 등 컴퓨터가 스스로 학습할 수 없고 사람이 직접 지정해주어야 하는 값입니다.<br />
최적의 하이퍼 파라미터 값을 찾는 과정을 튜닝이라고 하는데 테스트 데이터를 튜닝하는데 사용하게 되면 신경망이 테스트 데이터에 맞춰지기 때문에 신뢰할 수 없는 정확도가 나오게 됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="n">x_val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">partial_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span> 
<span class="n">partial_y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">partial_x_train</span><span class="p">,</span>
                    <span class="n">partial_y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>2023-06-09 13:17:53.944718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2023-06-09 13:17:55.109637: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>fit 메소드로 리턴된 history 객체에는 각 epoch별 훈련 데이터의 손실함수, 정확도 값 그리고 검증 데이터의 손실함수, 정확도 값이 사전형태로 저장되어 있습니다.</p>

<p>다음은 각 epoch별 훈련 데이터의 손실함수 값과 검증 데이터의 손실함수 값을 나타낸 그래프 입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">"loss"</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"bo"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Training loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Validation loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s">"Training and validation loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/122070432/244593944-889dc68b-9d4b-41da-bc96-a91f53a06bf4.png" alt="png" /></p>

<p>훈련 데이터의 손실함수값은 0으로 수렴하는데 반해 검증 데이터의 값은 3 epoch 이후로 증가하는 것을 확인할 수 있습니다.<br />
신경망의 가중치들이 훈련 데이터에 지나치게 맞춰지게 되니, 즉 과적합이 발생하여 이런 현상이 나타납니다. 
과적합을 막기 위해서는 여러가지 방법이 있으나 이번엔 그저 epoch를 낮춰서 과적합이 일어나기 전까지만 학습해보겠습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="nc">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10000</span><span class="p">,),</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">),</span>
    <span class="nc">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">),</span>
    <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"rmsprop"</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">"binary_crossentropy"</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="s">"accuracy"</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre>2023-06-09 13:24:15.761915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.


 22/782 [..............................] - ETA: 3s - loss: 0.2957 - accuracy: 0.8920

2023-06-09 13:24:19.225945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.


782/782 [==============================] - 4s 5ms/step - loss: 0.3083 - accuracy: 0.8786


[0.30827558040618896, 0.878600001335144]
</pre></td></tr></tbody></table></code></pre></div></div>

<p>손실함수값은 0.3 정도, 정확도는 0.87 정도로 나왔네요.<br />
<code class="language-plaintext highlighter-rouge">predict</code>메소드로 테스트 데이터의 예측 확률을 확인해볼까요?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>782/782 [==============================] - 3s 3ms/step
[0.22998719]
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>0
</pre></td></tr></tbody></table></code></pre></div></div>

<p>예측 확률이 0.5보다 낮은 걸보니 모델은 부정 리뷰라고 예측했고 라벨을 확인해보니 맞춘걸 알 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">decoded_review</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">reverse_word_index</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="s">"?"</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">decoded_review</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss
</pre></td></tr></tbody></table></code></pre></div></div>

<p>디코딩해서 살펴보니 악평이 맞네요</p>

<p>이 모델을 활용하여 어떤 단어를 입력받았을 때 단어에 대해 긍정 리뷰에서의 등장빈도와 부정 리뷰에서의 등장 빈도를 출력하는 함수를 만들 수 있습니다.<br />
예를 들면, ‘good’이라는 단어를 입력 받으면 ‘good’이라는 단어가 긍정 리뷰에 등장한 빈도와 부정 리뷰에 등장한 빈도가 출력됩니다. 당연히 긍정 리뷰에 등장한 빈도가 더 많겠죠?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>782/782 [==============================] - 3s 4ms/step
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">frequency</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"어휘 : </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="n">positive</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">:</span>
            <span class="n">positive</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="n">negative</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">&lt;</span><span class="mf">0.5</span><span class="p">:</span>
            <span class="n">negative</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="n">test_positive</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">positive</span><span class="p">]</span>
    <span class="n">count</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">test_positive</span><span class="p">:</span>
        <span class="n">count</span><span class="o">+=</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span><span class="o">==</span><span class="p">(</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">+</span><span class="mi">3</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"긍정 리뷰에서 등장 빈도 : </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="n">test_negative</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">negative</span><span class="p">]</span>
    <span class="n">count</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">test_negative</span><span class="p">:</span>
        <span class="n">count</span><span class="o">+=</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span><span class="o">==</span><span class="p">(</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">+</span><span class="mi">3</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"부정 리뷰에서 등장 빈도 : </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"good"</span><span class="p">,</span><span class="s">"bad"</span><span class="p">,</span><span class="s">"best"</span><span class="p">]:</span>
    <span class="nf">frequency</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"="</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre>어휘 : good
긍정 리뷰에서 등장 빈도 : 7908
부정 리뷰에서 등장 빈도 : 6646
==================================================
어휘 : bad
긍정 리뷰에서 등장 빈도 : 2135
부정 리뷰에서 등장 빈도 : 6988
==================================================
어휘 : best
긍정 리뷰에서 등장 빈도 : 4445
부정 리뷰에서 등장 빈도 : 1735
==================================================
</pre></td></tr></tbody></table></code></pre></div></div>

<p>IMDB 데이터를 이용해 이진 분류를 해보았습니다.</p>

<p>다음 포스팅에서는 로이터 뉴스 데이터셋을 활용하여 다중분류를 해보도록 하겠습니다.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#keras" class="page__taxonomy-item p-category" rel="tag">keras</a><span class="sep">, </span>
    
      <a href="/tags/#ml" class="page__taxonomy-item p-category" rel="tag">ml</a><span class="sep">, </span>
    
      <a href="/tags/#python" class="page__taxonomy-item p-category" rel="tag">python</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#keras" class="page__taxonomy-item p-category" rel="tag">Keras</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2023-06-06T00:00:00+09:00">June 6, 2023</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%5Bkeras+%EB%BF%8C%EC%8B%9C%EA%B8%B0%5D+%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC%EB%A5%BC+%EC%9D%B4%EC%9A%A9%ED%95%9C+%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98%20http%3A%2F%2Flocalhost%3A4000%2Fkeras%2Fkeras_02%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fkeras%2Fkeras_02%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fkeras%2Fkeras_02%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/keras/keras_01/" class="pagination--pager" title="[keras 뿌시기] Sequential API
">이전</a>
    
    
      <a href="#" class="pagination--pager disabled">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">참고</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/keras/keras_01/" rel="permalink">[keras 뿌시기] Sequential API
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-06-02T00:00:00+09:00">June 2, 2023</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          9 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Sequential API
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/programmers/programmers-network-solution/" rel="permalink">[Programmers] 네트워크
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-02-19T00:00:00+09:00">February 19, 2023</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">프로그래머스 네트워크 문제풀이
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dacon/prediction-of-trevel-product/" rel="permalink">[Dacon] 여행상품 신청예측
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-02-02T00:00:00+09:00">February 2, 2023</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          43 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">데이콘 Basic 여행상품 신청예측
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/programmers/programmers-%EC%9D%B4%EB%AA%A8%ED%8B%B0%EC%BD%98%ED%95%A0%EC%9D%B8%ED%96%89%EC%82%AC/" rel="permalink">[Programmers] 이모티콘 할인행사
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-01-30T00:00:00+09:00">January 30, 2023</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          3 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">프로그래머스 이모티콘 할인행사
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Tae Hyeon Kim. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
